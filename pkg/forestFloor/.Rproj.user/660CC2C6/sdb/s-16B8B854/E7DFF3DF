{
    "contents" : "\n# Methods:\n#m1 print output\nprint.forestFloor = function(x,...) {\n cat(\"this is a forestFloor('x') object \\n\nthis object can be plotted in 2D with plot(x), see help(plot.forestFloor) \\n\nthis object can be plotted in 3D with show3d(x), see help(show3d) \\n\n\\n\nx contains following internal elements: \\n \",with(x,ls()))\n}\n\n#m2 plot output\nplot.forestFloor = function(x,\n                            #colour_by=1,  #remove\n                            #col_axis = 1, #remove\n                            plot_seq=NULL, \n                            #alpha=\"auto\", #remove\n                            limitY=TRUE,\n                            order_by_importance=TRUE, \n                            #external.col=NULL, #remove\n                            cropXaxes=NULL, \n                            crop_limit=4,\n                            ...)\n  {\n  \n  pars = par(no.readonly = TRUE) #save previous graphical par(emeters)\n  par(mar=c(2,2,1,1),cex=.5) #changing par, narrowing plot margins, smaller points\n  \n  #short for phys.val and feature contribution in object\n  X = x$X\n  FCs = x$FCmatrix\n  \n#obsolete\n#   #Auto setting transparancy variable. The more obs, the more transparrency\n#   if(alpha==\"auto\") alpha = min(max(400/dim(X)[1],0.2),1)\n#   \n  #If no sequnce, choosing to plot first 18 variables\n  if(is.null(plot_seq)) plot_seq = 1:min(dim(X)[2],24)\n  \n  #make catogorical features numeric, save jitter.template\n  jitter.template=rep(FALSE,dim(X)[2]) #list of what features are catagorical\n  as.numeric.factor <- function(x) {match(x,levels(x))}\n  for(i in 1:dim(X)[2]) {\n    if(is.factor(X[,i])) {\n      jitter.template[i]=TRUE\n      this.fac=as.numeric.factor(X[,i])\n      X[,i] = this.fac\n    }\n    if(is.character(X[,i])) X[,i] = as.numeric(X[,i])\n  } \n  \n  ##get dimensions of plots\n  n.plots = min(dim(X)[2],length(plot_seq))\n  plotdims.y = min(ceiling(n.plots/3),5)\n  plotdims.x = min(3 , n.plots)\n  par(mfrow=c(plotdims.y,plotdims.x))\n  \n  ##get importance for plotting\n  imp = x$importance     #fetch importance\n  imp.ind = x$imp_ind    #fetch importance ranking/indices\n  \n  ##plot the n.plots most important variables\n  Xsd = 0:1 #initialize Xsd\n  if(!order_by_importance) imp.ind=sort(imp.ind) #optinal removal of importance order\n  for(i in plot_seq) {\n    \n    if(i %in% cropXaxes && !is.null(cropXaxes)) {\n      limitX = TRUE\n      Xsd = box.outliers(as.numeric(X[,imp.ind[i]],2),limit=crop_limit,normalize=F)\n    } else {\n      limitX = FALSE\n    }\n    \n    plot(\n      data.frame( # data to plot\n        physical.value        = jitter(X[,imp.ind[i]],factor=jitter.template[imp.ind[i]]*2),\n        partial.contribution  = FCs[,imp.ind[i]]\n      ),\n      main = names(imp)[imp.ind[i]],\n      ylim = list(NULL,range(FCs))[[limitY+1]], #same Yaxis if limitY == TRUE\n      xlim = list(NULL,range(Xsd))[[limitX+1]],\n      ...\n    )\n  }\n  pars = with(pars,if(exists(\"pin\")) {\n    rm(pin)\n    return(mget(ls()))\n    }) \n  par(pars)\n}\n\n#f1a 3d show function\nshow3d_new = function(ff,\n                      Xi  = 1:2,\n                      FCi = NULL,\n                      col = \"#12345678\",    \n                      sortByImportance = TRUE,\n                      surface=TRUE,   \n                      combineFC = sum,  \n                      zoom=1.2,       \n                      grid.lines=30,  \n                      limit=3, \n                      kknnGrid.args = alist(),  \n                      plot.rgl.args = alist(),  \n                      surf.rgl.args = alist()   \n                      ) {\n  if(class(ff)!=\"forestFloor\") stop(\"ff, must be of class forestFloor\")\n  if(length(Xi)!=2) {\n    warning(\"Xi should be of length 2, if 1 first elements is used twice, if >2 only two first elements is used\")\n    if(length(Xi) > 2) Xi=Xi[1:2] else Xi = Xi[c(1,1)]\n  }\n  if(!all(Xi %in% 1:dim(ff$X)[2]))   stop( \"input  Xi points to columns indices out of range of feature matrix ff$X\")\n  if(is.null(FCi)) FCi=Xi\n  if(!all(FCi %in% 1:dim(ff$FCmatrix)[2]) && length(FCi)>0) stop(\"input FCi points to columns indices out of range of feature matrix ff$X\")\n  \n  #fetch selected coloums from object\n  X = ff$X[,Xi]\n  FC = ff$FCmatrix[,FCi]\n  \n  #define xy coordinates from features and z from feature contributions\n  xaxis = X[,1]\n  yaxis = X[,2]\n  if(length(FCi)==1) zaxis = FC else zaxis = apply(FC,1,combineFC) #if multiple FCis these will summed to one value.\n  \n  #fixing categorical features\n  as.numeric.factor <- function(x,rearrange=TRUE) {\n    if(rearrange) x = match(x,levels(droplevels(x))) else x = match(x,levels(x))\n  }\n  if(is.factor(xaxis)) xaxis = as.numeric.factor(xaxis)\n  if(is.factor(yaxis)) yaxis = as.numeric.factor(yaxis)\n  if(is.factor(zaxis)) zaxis = as.numeric.factor(zaxis)\n\n  #plotting points\n  #merge current/user, wrapper arguments for plot3d in proritized order\n  wrapper_arg = list(x=xaxis, y=yaxis, z=zaxis, col=col,\n                xlab=names(X)[1],ylab=names(X)[2],zlab=paste(names(ff$X[,FCi]),collapse=\" - \"),\n                alpha=.4,size=3,scale=.7,avoidFreeType = TRUE,add=FALSE)\n  calling_arg = append.overwrite.alists(plot.rgl.args,wrapper_arg)\n  do.call(\"plot3d\",args=calling_arg)\n  \n  #plotting surface\n  #merge arguments again\n  if(surface) {\n    #compute grid\n  grid = convolute_grid(ff, Xvars=Xi, FCvars=FCi, limit=limit, grid=grid.lines, zoom=zoom,  userArgs.kknn = kknnGrid.args)\n  wrapper_arg = alist(x=unique(grid[,2]),y=unique(grid[,3]),z=grid[,1],add=TRUE,alpha=0.2,col=c(\"grey\",\"black\")) #args defined in this wrapper function\n  calling_arg = append.overwrite.alists(surf.rgl.args,wrapper_arg)   \n  do.call(\"persp3d\",args=calling_arg)\n  }\n}\n\n\n\n\n#f2 - show vec plot 2D and 3D\nvec.plot = function(model,X,i.var,grid.lines=100,VEC.function=mean,zoom=1,limitY=F,col=\"#20202050\") {\n  \n  #compute grid range\n  d = length(i.var)\n  scales = lapply(i.var, function(i) {\n    rXi = range(X[,i])\n    span = abs(rXi[2]-rXi[1])*zoom/2\n    center = mean(rXi)\n    seq(center-span,center+span,length.out=grid.lines)\n  })\n  \n  #expand grid range to a n-dimensional VEC-space and predict by model\n  anchor.points = as.matrix(expand.grid(scales),dimnames=NULL)\n  Xgeneralized=apply(X,2,VEC.function)    \n  Xtest.vec = data.frame(t(replicate(dim(anchor.points)[1],Xgeneralized)))\n  Xtest.vec[,i.var] = anchor.points\n  yhat.vec = predict(model,Xtest.vec)\n  \n  #add observations to VEC-space\n  values.to.plot=X[,i.var]\n  Xmean=apply(X,2,VEC.function)\n  Xtest.obs = data.frame(t(replicate(dim(X)[1],Xgeneralized)))\n  Xtest.obs[,i.var] = values.to.plot\n  yhat.obs =  predict(model, Xtest.obs)\n  \n  #plot VEC-space versus predictions (only 2D and 3D plot supported)\n  if(d==2) { #if 2D VEC space\n    plot3d(x=values.to.plot[,1],y=values.to.plot[,2],z=yhat.obs,\n           xlab=names(X)[i.var][1],ylab=names(X)[i.var][2],main=\"VEC-SURFACE\",col=col)\n    surface3d(x=scales[[1]],\n              y=scales[[2]],\n              z=yhat.vec,col=\"#404080\",size=4,alpha=0.4)\n  }else{ #otherwise if 1D VEC-space\n    if(limitY) {ylim = range(model$y)} else {ylim = NULL}\n    plot(x=scales[[1]],y=yhat.vec,col=\"red\",type=\"l\",xlab=names(X)[i.var][1],ylim=ylim)\n    points(values.to.plot,yhat.obs)\n  }\n}\n\n\n\n#f3 input a forestFloor object, computes convoluted feature contributions with kknn\n#outout a new ff object as input with attached ff$FCfit\n#kknn arguments can be accessed directly from this wrapper by userArgs.kknn\n#if conflicting with wrappe\nconvolute_ff = function(ff,\n                        these.vars=NULL,\n                        k.fun=function() round(sqrt(n.obs)/2),\n                        userArgs.kknn = alist(kernel=\"gaussian\")\n                        ) {\n  \n  n.obs=dim(ff$X)[1]\n  n.vars=dim(ff$X)[2]\n  k=k.fun()\n  if(is.null(these.vars)) these.vars = 1:n.vars\n  \n  \n  #merge user and wrapper args\n  Data = \"I only exist to satisfy R cmd CHECK\" #dummy declaration\n  defaultArgs.kknn = alist(formula=fc~.,data=Data,kmax=k,kernel=\"gaussian\")\n  kknn.args=append.overwrite.alists(userArgs.kknn,defaultArgs.kknn)\n  \n  #iterate for seleceted variables\n  ff$FCfit = sapply(these.vars, function(this.var) {\n    Data = data.frame(fc=ff$FCmatrix[,this.var],x=ff$X[,this.var])\n    knn.obj = do.call(\"train.kknn\",kknn.args)$fitted.values\n    knn.obj[[length(knn.obj)]]\n  })\n  ff  \n}\n\n\n#f3 input a forestFloor object, as convolute_ff but do not iterate all variables. Instead wrapper will use\n#kknn to convolute a designated featureContribution with designated features - oftenly the corresponding features.\nconvolute_ff2 = function(ff,\n                        Xvars,\n                        FCvars = NULL,\n                        k.fun=function() round(sqrt(n.obs)/2),\n                        userArgs.kknn = alist(kernel=\"gaussian\")\n) {\n  if(is.null(FCvars)) FCvars = Xvars\n  n.obs=dim(ff$X)[1]\n  k=k.fun()\n    \n  #merge user and wrapper args\n  defaultArgs.kknn = alist(formula=fc~.,data=Data,kmax=k,kernel=\"gaussian\")\n  kknn.args=append.overwrite.alists(userArgs.kknn,defaultArgs.kknn)\n  \n  #collect coloumns\n  if(length(FCvars)>1) {\n    fc = apply(ff$FCmatrix[,FCvars],1,sum)\n  } else {\n    fc = ff$FCmatrix[,FCvars]\n  }\n  x = ff$X[,Xvars]\n  \n  #compute topology\n    Data = data.frame(fc=fc,x=x)\n    knn.obj = do.call(\"train.kknn\",kknn.args)$fitted.values\n    out = knn.obj[[length(knn.obj)]]\n}\n\n#f4 input a forestFloor object, as convolute_ff but do not iterate all variables. Instead wrapper will use\n#kknn to convolute a designated featureContribution with designated features - oftenly the corresponding features.\nconvolute_grid = function(ff,\n                          Xvars,\n                          FCvars = NULL,\n                          grid = 30,\n                          limit = 3,\n                          zoom = 3,\n                          k.fun=function() round(sqrt(n.obs)/2),\n                          userArgs.kknn = alist(kernel=\"gaussian\")\n) {\n  \n  #input defaults\n  if(is.null(FCvars)) FCvars = Xvars\n  n.obs=dim(ff$X)[1]\n  k=k.fun() # will be overided if a \"k=\" argument is provided in userArgs.kknn-list\n  \n  #collect coloumns of data\n  if(length(FCvars)>1) {\n    fc = apply(ff$FCmatrix[,FCvars],1,sum)\n  } else {\n    fc = ff$FCmatrix[,FCvars]\n  }\n  X = ff$X[,Xvars]\n  \n  #make grid, or use external grid if provided\n  if(length(grid)==1) {\n    X = box.outliers(X,limit=limit,normalize=F)\n    get.seq = function(x) {\n      upper = (max(x) - mean(x)) * zoom\n      lower = (min(x) - mean(x)) * zoom\n      seq(lower+mean(x), upper+mean(x),length.out=grid)\n    }\n    ite.val=lapply(1:dim(X)[2],function(i) get.seq(X[,i])) #for each variable define span of grid\n    gridX = as.data.frame(expand.grid(ite.val))\n    names(gridX) = names(X)\n    \n    ##WOUPS NEVERMIND it worked...\n#     #could not make list of vectors work with expand.grid as doc promises\n#     #this hack calls expand.grid with specified arguments\n#     \n#     #hack - make charecter string of appropiate code\n#     run.this = \"alist(\"\n#     for(i in 1:dim(X)[2]) run.this = paste(run.this,names(X)[i],\" = ite.val[,\",i,\"],\",sep=\"\")\n#     run.this = substr(run.this,1,nchar(run.this)-1)\n#     run.this = paste(run.this,\")\")\n#     #hack - parse and evaluate string into a argument list of one argument for each dimension\n#     arg.list = eval(parse(text=run.this))\n#     #call expand.grid with specified arguments\n#     gridX=as.data.frame(do.call(expand.grid,arg.list)) #grid coordinates\n\n  } else {\n    gridX = grid\n  }\n  \n  #prepare data\n  Data = data.frame(fc=fc,x=ff$X[,Xvars])\n  gridX = data.frame(x=gridX)\n  \n  #merge user args and args of this wrapper function, user args have priority\n  defaultArgs.kknn = alist(formula=fc~.,train=Data,k=k,kernel=\"gaussian\",test=gridX)\n  kknn.args=append.overwrite.alists(userArgs.kknn,defaultArgs.kknn)\n    \n  #execute kknn function and retrive convolution\n  gridFC = do.call(\"kknn\",kknn.args)$fitted.values\n  \n  #gather results in data frame, with convoluted feature contributinos in grid\n  return(data.frame(fc = gridFC,gridX))\n}\n\n\n\n# #sf5 scale data and grid, to allow knn \n# scale.by = function(scale.this,by.this) {\n#   center = attributes(by.this)$'scaled:center'\n#   scales = attributes(by.this)$'scaled:scale'\n#   nvars = dim(scale.this)[2]\n#   sapply(1:nvars, function(i) (scale.this[,i]-center[i])/scales[i])\n# }\n\n\n\n\n#sf6  reduce outliers to within limit of 1.5 std.dev and/or output as normalized \nbox.outliers = function(x,limit=1.5,normalize=TRUE) {\n  \n  sx=scale(x)\n  if(limit!=FALSE) {\n    sx[ sx>limit] =  limit\n    sx[-sx>limit] = -limit\n  }\n  \n  if(normalize) { \n    sx.span = max(sx) - min(sx)\n    sx = sx - min(sx)\n    sx = sx / sx.span\n  } else {\n    obs=attributes(sx)$\"dim\"[1]\n    if(dim(sx)[2]>1) {\n    sx = sx * t(replicate(obs,attributes(sx)$\"scaled:scale\")) +\n              t(replicate(obs,attributes(sx)$\"scaled:center\"))\n    } else {\n    sx  = sx * attributes(sx)$\"scaled:scale\" + attributes(sx)$\"scaled:center\" \n    }\n  }\n\n  if(class(x)==\"data.frame\") {\n    sx = as.data.frame(sx,row.names=row.names(x))\n    names(sx) = names(x)\n  }\n  return(sx)\n}\n\n# #sf7  - calculate deviance from surface\n# surf.error = function() {\n#   outs=replicate(knnBag, {  #the following is replicated/performed severeal ~20 times\n#     this.boot.ind = sample(dim(XY)[1]*bag.ratio,replace=T) #pick a bootstrap from samples             \n#     sXY = scale(XY[this.boot.ind,])  #scale bootstrap to uni-variance\n#     sgridXY = scale.by(scale.this=gridXY,by.this=sXY) #let grid be scaled as this bootstrap was scaled to sXY\n#     out=knn.reg(train=sXY,\n#                 test=sgridXY,\n#                 y=axisval$z[this.boot.ind],\n#                 k=k,\n#                 algorithm=\"kd_tree\")$pred  #predict grid from bootstrap of samples\n#   })\n# }\n\n# #sf7 estimate surface with kNNbag, depends on \"sf5 - scale.by\"\n# kNN.surf = function(knnBag,\n#                     XY,\n#                     gridXY,\n#                     k,\n#                     y,\n#                     bag.ratio=.8,\n#                     replace=TRUE) {\n#   outs=replicate(knnBag, {  #the following is replicated/performed severeal ~20 times\n#     this.boot.ind = sample(dim(XY)[1]*bag.ratio,replace=TRUE) #pick a bootstrap from samples             \n#     sXY = scale(XY[this.boot.ind,])  #scale bootstrap to uni-variance\n#     sgridXY = scale.by(scale.this=gridXY,by.this=sXY) #let grid be scaled as this bootstrap was scaled to sXY\n#     out=knn.reg(train=sXY,\n#                 test=sgridXY,\n#                 y=y[this.boot.ind],\n#                 k=k,\n#                 algorithm=\"kd_tree\")$pred  #predict grid from bootstrap of samples\n#   })\n#   out = apply(outs,1,mean) # collect predictions\n#   return(out)\n# }\n\n\n\n#sf8 neat function to help increase adaptability of wrappers, default args defined by wrapper. User can \n#input an alist and by this function the wrapper will append new args and overwrite conflicting arguments.\n#one set of args either user or defaults are set as master\nappend.overwrite.alists= function(masterArgs,slaveArgs) {\n  slaveArgs.to.overwrite = names(slaveArgs) %in% names(masterArgs)\n  for(i in which(slaveArgs.to.overwrite))  slaveArgs[i] = masterArgs[match(names(slaveArgs[i]),names(masterArgs))]\n  masterArgs.to.append = !(names(masterArgs) %in% names(slaveArgs))\n  c(slaveArgs,masterArgs[masterArgs.to.append])\n}\n#sf9: colour function\nfcol = function(ff,\n                cols = NULL,\n                X.matrix = TRUE,\n                hue = NULL,\n                saturation = NULL,\n                brightness = NULL,\n                hue.range  = NULL,\n                sat.range  = NULL,\n                bri.range  = NULL,\n                alpha = NULL,\n                RGB = NULL,\n                max.df=3,\n                imp.weight = NULL,\n                imp.exp = 1,\n                outlier.lim = 3,\n                RGB.exp = NULL) {\n  \n  ##ssf8.1: is between function\n  ib <- function(x, low, high) (x -low) * (high-x) > 0\n  ##ssf8.2: move center range of vector at mid with new width of span\n  span <- function(x, mid, width) ((x-min(x))/(max(x)-min(x))-0.5)*width+mid\n  ##ssf8.3: compute widest range possible with given brightness or saturation\n  auto.range = function(level,low=0,high=1) abs(min(level-low,high-level))*2\n  ##ssf8.4: contain a vector such that any out side limits will be reduced to limits\n  contain = function(x,low=0,high=1) {\n    x[x>high]=high\n    x[x<low ]=low\n    x\n  }\n  \n  \n  #get/check data.frame/matrix, convert to df, remove outliers and normalize\n  if(class(ff)==\"forestFloor\") {\n    if(X.matrix) colM = ff$X else colM = ff$FCmatrix\n    if(is.null(imp.weight)) imp.weight=TRUE\n  } else {\n    colM=ff\n    if(is.null(imp.weight)) imp.weight=FALSE\n  }\n  if(!class(colM) %in% c(\"data.frame\",\"matrix\")) {\n    stop(paste(class(colM),\"is neither matrix or data.frame\"))\n  }\n  colM = data.frame(colM)\n  \n  #checking selected cols\n  if(is.null(cols)) cols = 1:dim(colM)[2] #select all columns\n  if(length(cols)<1 || !is.numeric(cols) || any(!cols %in% 1:dim(colM)[2])) {\n    stop(\"no cols selected or is not integer/numeric or wrong coloumns\")\n  }\n  print(\"here1\")\n  sel.colM = data.frame(colM[,cols])    #use only selected columns\n  sel.cols = 1:length(cols) #update cols to match new col.indices of colM\n  \n  #auto choose colour system: RGB=TRUE is colours system one\n  if(is.null(RGB)) if(length(cols)==1) RGB=TRUE else RGB=FALSE\n  if(!RGB) {\n    if(is.null(saturation)) saturation = .85\n    if(is.null(brightness)) brightness = .75\n    if(is.null(hue))        hue = .25\n  } else {\n    if(is.null(saturation)) saturation = 1\n    if(is.null(brightness)) brightness = .75\n    if(is.null(hue))        hue = .66    \n    if(is.null(RGB.exp))    RGB.exp=1.2\n    if(is.null(hue.range))  hue.range=2\n  }\n  \n  \n  \n  #force catogorical features to become numeric\n   as.numeric.factor <- function(x) {match(x,levels(x))}\n  for(i in 1:dim(sel.colM)[2]) {\n    if(is.factor(sel.colM[,i])) {\n      this.fac=as.numeric.factor(sel.colM[,i])\n      sel.colM[,i] = this.fac\n    }\n    if(is.character(sel.colM[,i])) sel.colM[,i] = as.numeric(sel.colM[,i])\n  } \n  print(\"here2\")\n  #restrain outliers by limit(std.dev) and normalize\n  sel.colM = box.outliers(sel.colM,limit=outlier.lim)\n  \n  \n  #inflating data by importance\n  if(imp.weight && length(cols)>1) {\n    if(class(ff)==\"forestFloor\") {\n      sel.imp = ff$importance[cols]\n      non.negative.imp = sel.imp+min(sel.imp)\n      sumnorm.imp =  non.negative.imp / sum(non.negative.imp)\n      exp.imp = sumnorm.imp ^ imp.exp #included weight exponent\n      impM = t(replicate(dim(colM)[1],exp.imp))\n      sel.colM = sel.colM*impM #inflate by importance\n      sel.colM = sel.colM / max(sel.colM)\n    } else {warning(\"importance weighting only possible for class 'forestFloor'\")}\n  }\n  print(\"here3\")\n  #Setting up ranges for colours\n  if(any(!c(class(hue),class(saturation),class(brightness)) %in% c(\"numeric\",\"integer\"))){\n    stop(\"hue, saturation and brightness must be of class numeric or integer\")\n  }\n  \n  #correct input to be within [0,1]\n  hue = hue - floor(hue)\n  saturation = max(min(saturation,1),0)\n  brightness = max(min(brightness,1),0)\n  \n  ###################\n  ###colours system A:  1-way gradient Red-Green-BLUE scale\n  \n  if(RGB==TRUE) {\n    if(is.null(bri.range)) bri.range=0.05\n    if(is.null(alpha)) alpha=.7\n    len.colM = box.outliers(sel.colM,limit=Inf)\n    if(dim(len.colM)[2]==1) nX = as.numeric(len.colM[,1]) else nX = as.numeric(apply(len.colM,1,mean))\n    #Colours = sapply(nX,function(x) rgb(x^2.3,1-x^2.7-(1-x)^2.7,(1-x)^2.3,alpha=0.6))\n    hsvcol    = t(sapply(nX,function(x) rgb2hsv(x^RGB.exp,\n                                                1-x^RGB.exp-(1-x)^RGB.exp,\n                                               (1-x)^RGB.exp)))\n    hue.vec = hsvcol[,1] * hue.range + hue\n    hue.vec[hue.vec>1] = hue.vec[hue.vec>1] - floor(hue.vec[hue.vec>1])\n    hsvcol[,1] = hue.vec\n    sat.range = auto.range(saturation)\n    hsvcol[,2] = span(hsvcol[,2],saturation,sat.range)\n    hsvcol[,2] = contain(hsvcol[,2])\n    bri.range = auto.range(brightness)\n    hsvcol[,3] = span(hsvcol[,3],brightness,bri.range)\n    hsvcol[,3] = contain(hsvcol[,3])\n    colours = apply(hsvcol,1,function(x) hsv(x[1],x[2],x[3],alpha=alpha))\n#     a = mget(ls())\n#     print(str(a))\n    return(colours) #function terminates with these colours\n  }\n  print(\"passed RGB\")\n  \n  ############\n  ##Colour system B: Hue, saturation, value, consist of a 1D, 2D and 3D scale\n  \n  \n  #if maxPC is less than n selected coloumns\n  #centering, no scaling and PCA is applied\n  #output scores is transformed to range [0,1]\n  #cols are correect to lower manifold number maxPC\n  col.df = length(cols)\n  if(col.df>max.df) {\n    len.colM = box.outliers(prcomp(sel.colM)$x[,1:max.df],limit=Inf)\n    col.df = max.df\n  } else {\n    len.colM = box.outliers(sel.colM,limit=Inf)\n  }\n  \n  \n  #define ranges if not defined for different dimensions\n  if(is.null(hue.range)) {\n    if(col.df==1) hue.range = .85\n    if(col.df==2) hue.range = 1 #circular no range lim needed\n    if(col.df==3) hue.range = 1 #circular no range lim needed\n  }\n  if(is.null(sat.range)) {\n    if(col.df==1) sat.range = \"not used\"\n    if(col.df==2) sat.range = auto.range(saturation)\n    if(col.df==3) sat.range = auto.range(saturation)\n  } \n  if(is.null(bri.range)) {\n    if(col.df==1) bri.range = \"not used\"\n    if(col.df==2) bri.range = \"not used\"\n    if(col.df==3) bri.range = auto.range(brightness)\n  }\n  if(is.null(alpha)) alpha = min(1,400/dim(len.colM)[1])\n  \n  \n  ##writing colour scale dependent on colour degrees of freedom(col.df)\n  #one way gradient\n  if(col.df==1) {\n    hue.vec = as.numeric(len.colM[,1]) * hue.range + hue\n    hue.vec[hue.vec>1] = hue.vec[hue.vec>1] - floor(hue.vec[hue.vec>1])\n    colours = hsv(h = hue.vec,\n                  s = saturation,\n                  v = brightness,\n                  alpha = alpha) #defining colour gradient along X3)\n  }\n  \n  #two way gradient\n  if(col.df==2) {\n    hsvcol = t(rgb2hsv(len.colM[,1],len.colM[,2],1-apply(len.colM,1,mean)))\n    hue.vec = hsvcol[,1] * hue.range + hue\n    hue.vec[hue.vec>1] = hue.vec[hue.vec>1] - 1\n    hsvcol[,1] = hue.vec\n    #saturation is proportional with distance to center\n    hsvcol[,2] = ((len.colM[,1]-mean(len.colM[,1]))^2\n                  +(len.colM[,2]-mean(len.colM[,2]))^2)^sat.range * saturation\n    hsvcol[,2] = hsvcol[,2] / max(hsvcol[,2])\n    hsvcol[,3] = brightness\n    colours = hsv(hsvcol[,1],hsvcol[,2],hsvcol[,3],alpha=alpha)\n  }  \n  \n  #three way gradient\n  if(col.df==3) {  \n    hsvcol      = t(rgb2hsv(len.colM[,1],len.colM[,2],len.colM[,3]))\n    #set hue\n    hue.vec     = hsvcol[,1] * hue.range + hue\n    hue.vec[hue.vec>1] = hue.vec[hue.vec>1] - 1\n    hsvcol[,1]  = hue.vec\n    #set sat\n    span.sat    = span(hsvcol[,2],saturation,sat.range)\n    hsvcol[,2]  = contain(span.sat)\n    #set bri\n    mean.bri    = apply(len.colM,1,mean)\n    span.bri    = span(mean.bri,brightness,bri.range)\n    hsvcol[,3]  = contain(span.bri)\n    colours     = hsv(hsvcol[,1],hsvcol[,2],hsvcol[,3],alpha=alpha)\n  }\n  print(sat.range)\n  return(colours)\n}\n\n\n\nforestFloor = function(rfo,X,calc_np=FALSE) { \n  \n  #check the RFobject have a inbag\n  if(is.null(rfo$inbag)) stop(\"input randomForest-object have no inbag, set keep.inbag=T,\ntry, randomForest(X,Y,keep.inbag=T) for regression where Y is numeric\nand, cinbag(X,Y,keep.inbag=T,keep.forest=T) for binary-class where Y is factor\n..cinbag is from trimTrees package...\nerror condition: if(is.null(rfo$inbag))\")\n   \n  #make node status a integer matrix\n  ns = rfo$forest$nodestatus\n  storage.mode(ns) = \"integer\"\n   \n  \n  #translate binary classification RF-object, to regression mode\n  if(rfo$type==\"classification\") {\n    if(length(levels(rfo$y))!=2) stop(\"no multiclass, must be binary classification.\n                                      error condition: if(length(levels(rfo$y))!=2\")\n    print(\"RF is classification, converting factors/categories to numeric 0 an 1\")\n    Y = as.numeric((rfo$y))-1\n    cat(\" defining\",levels(rfo$y)[1],\" as 0\\n defining\",levels(rfo$y)[2],\"as 1\")\n    rfo$forest$leftDaughter  = rfo$forest$treemap[,1,] #translate daughter representation to regression mode\n    rfo$forest$rightDaughter = rfo$forest$treemap[,2,] \n    ns[ns==1] = -3  ##translate nodestatus representation to regression mode\n    if(is.null(\"rfo$inbagCount\")) stop(\"classification topology not supported with randomForest() {randomForest}\nGrow forest with cinbag::trimTrees instead of randomForest(). The two\nfunctions are identical, except cinbag() entails a more detailed inbag record,\nwhich is needed to estimate binary node probabilities.\nerror condition:  if(is.null('rfo$inbagCount'))\")\n    \n    if(!calc_np) stop(\"node predictions must be re-calculated for random forest of type classification, set calc_np=T)\nerror conditions: if(!calc_np && rfo$type='classification')\")\n    \n    inbag = rfo$inbagCount\n    } else {\n    Y=rfo$y\n    inbag = rfo$inbag\n  }\n\n\n  #preparing data, indice-correction could be moved to C++\n  #a - This should be fethed from RF-object, flat interface\n  ld = rfo$forest$leftDaughter-1 #indice correction, first element is 0 in C++ and 1 in R.\n  storage.mode(ld) = \"integer\"\n  rd = rfo$forest$rightDaughter-1\n  storage.mode(rd) = \"integer\"\n  bv = rfo$forest$bestvar-1\n  storage.mode(bv) = \"integer\"\n  np = rfo$forest$nodepred\n  storage.mode(np) = \"double\"\n  bs = rfo$forest$xbestsplit\n  storage.mode(bs) = \"double\"\n  ib = inbag\n  storage.mode(ib) = \"integer\"\n  Yd = as.numeric(Y)\n  storage.mode(Yd) = \"double\"\n  ot  = rfo$oob.times\n  storage.mode(ot) = \"integer\"\n \n \n  ##recording types of variables\n  xlevels = unlist(lapply(rfo$forest$xlevels,length),use.names=F)\n  xl = xlevels\n  storage.mode(xl) = \"integer\"\n  varsToBeConverted = xlevels>1\n\n  ##Converting X to Xd, all factors change to level numbers\n  Xd=X\n  for(i in 1:dim(Xd)[2]) {\n    if(varsToBeConverted[i]) {\n      Xd[,i] = as.numeric(Xd[,i])-1  \n    }\n  }  \n  Xd=as.matrix(Xd)\n  storage.mode(Xd) = \"double\"\n  \n  #outout variable\n  localIncrements = Xd*0\n  storage.mode(localIncrements) = \"double\"\n  \n  #should activities of nodes be reestimated(true) or reused from randomForest object(false)\n  calculate_node_pred=calc_np\n    \n  # C++ function, recursively finding increments of all nodes of all trees\n  # where OOB samples are present. vars, obs and ntree is \"passed by number\"\n  # Anything else is passed by reference. Found increments are imediately\n  # summed to localIncrements matrix.\n  recTree(\n    #passed by number\n    vars=dim(X)[2], \n    obs=dim(X)[1],             \n    ntree=rfo$ntree,\n    calculate_node_pred=calculate_node_pred,\n    #passed by reference\n    X=Xd,  #training data, double matrix [obs,vars] \n    Y=Yd,\n    leftDaughter = ld,  #row indices of left subnodes, integer matrix [nrnodes,ntree] \n    rightDaughter = rd, #...\n    nodestatus = ns,    #weather node is terminal or not,      \n    xbestsplit = bs,          \n    nodepred = np,          \n    bestvar = bv,\n    inbag = ib,\n    varLevels = xl,\n    ot,  #oob.times\n    localIncrements = localIncrements #output is written directly to localIncrements from C++\n  )\n  \n  \n  \n#writing out list\n  imp = as.matrix(rfo$importance)[,1]\n  out = list(X=X,Y=Y,\n             importance = imp,\n             imp_ind = sort(imp,decreasing=TRUE,index.return=TRUE)$ix,\n             FCmatrix = localIncrements\n  )\n  class(out) = \"forestFloor\"\n  return(out)\n}",
    "created" : 1418485620292.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "870509896",
    "id" : "E7DFF3DF",
    "lastKnownWriteTime" : 1427705811,
    "path" : "~/Documents/PHD/Rlocal/svnff/forestfloor/pkg/forestFloor/R/forestFloor_source.R",
    "project_path" : "R/forestFloor_source.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}